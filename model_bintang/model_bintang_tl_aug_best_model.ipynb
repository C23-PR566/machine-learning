{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "qYhZOgC7PlUy"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SignABC - BISINDO Sign Language Learning App for Children\n",
        "\n",
        "<div class=\"alert alert-block alert-success\"> \n",
        "ðŸ“Œ This notebook is created for a capstone project, we are creating a learning app for children to help them learn about BISINDO sign language.\n",
        "</div>"
      ],
      "metadata": {
        "id": "aK7vqVSpoa7r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dependencies"
      ],
      "metadata": {
        "id": "hGqo00j9pqwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflowjs"
      ],
      "metadata": {
        "id": "sBPBECxrsVV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlOBlX8boE_l"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow_hub as hub\n",
        "# import tensorflowjs as tfjs\n",
        "\n",
        "from google.colab import drive, files\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import load_img, img_to_array"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "D3l80HbNAVEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "# drive.mount('/content/drive/')\n",
        "\n",
        "# Unzip dataset file\n",
        "# !unzip \"/content/drive/MyDrive/Capstone Project ML/Zipped dataset/Dataset_Experimen_Khresna/Dataset_KhresnaV4(NoSplit, NoPersonInBackground, NoAug).zip\" -d \"/content\"\n",
        "# !unzip \"/content/drive/Shareddrives/Capstone ML/Dataset Shared Drive/Dataset_BintangV0.zip\" -d \"/content\""
      ],
      "metadata": {
        "id": "fdbb9CxmAWd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset path\n",
        "path = \"/content/Dataset_BintangV0\"\n",
        "data_dir = pathlib.Path(path)\n",
        "\n",
        "# Image count\n",
        "image_count = len(list(data_dir.glob('*/*.jpg'))) + len(list(data_dir.glob('*/*.JPG'))) + len(list(data_dir.glob('*/*.png'))) + len(list(data_dir.glob('*/*.PNG')))\n",
        "print(image_count)"
      ],
      "metadata": {
        "id": "WwNLA1CcEacP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c93cf35-670f-497c-90a0-b9401ff3915a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "0lZn6ooKvYxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset properties\n",
        "batch_size = 100\n",
        "img_height = 224\n",
        "img_width = 224"
      ],
      "metadata": {
        "id": "BOlx7pvFvYx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training dataset\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "WKDW597uvYx3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d27991be-9008-42cd-a0d4-1b33dad7492b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 13000 files belonging to 26 classes.\n",
            "Using 10400 files for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing dataset\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "VylZLYUBvYx3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76dbd2f4-6295-40b6-f00f-a40583e4eec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 13000 files belonging to 26 classes.\n",
            "Using 2600 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Labels list\n",
        "class_names = np.array(train_ds.class_names)\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "1KhUqqojjPBW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57bf331c-fcfd-4d16-cc42-177abfa2597f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R'\n",
            " 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset sample\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "PJLE4NWNJnbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Normalize dataset\n",
        "# normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "# train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y)) \n",
        "# val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))"
      ],
      "metadata": {
        "id": "VOrssMqnvYx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Autotune cache and paralellization to improve performance\n",
        "# AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "# val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "GHfmth_YvYx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmentation layer\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "  tf.keras.layers.RandomContrast(factor=0.8),\n",
        "])"
      ],
      "metadata": {
        "id": "kcqo7aKva9tN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizization layer\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)"
      ],
      "metadata": {
        "id": "oHHOz4Z0z3sW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def preprocess(dataset, shuffle=False, augment=False):\n",
        "  # Resize and rescale all datasets.\n",
        "  dataset = dataset.map(lambda x, y: (normalization_layer(x), y), \n",
        "              num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "  if shuffle:\n",
        "    dataset = dataset.shuffle(1000)\n",
        "\n",
        "  # Use data augmentation only on the training set.\n",
        "  if augment:\n",
        "    dataset = dataset.map(lambda x, y: (data_augmentation(x, training=True), y), \n",
        "                num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "  # Use buffered prefetching on all datasets.\n",
        "  return dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "  # return dataset"
      ],
      "metadata": {
        "id": "hqwmmnPGc_1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply preprocessing to the dataset\n",
        "train_ds = preprocess(train_ds, shuffle=True, augment=False)\n",
        "val_ds = preprocess(val_ds)"
      ],
      "metadata": {
        "id": "ojIKhHqaz3sW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Without Transfer Learning\n",
        "\n"
      ],
      "metadata": {
        "id": "qYhZOgC7PlUy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture"
      ],
      "metadata": {
        "id": "dMY-w1I2N2Wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to create model\n",
        "def create_uncompiled_model():\n",
        "\n",
        "    num_classes = len(class_names)\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, 5, input_shape=(img_height, img_width, 3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dense(num_classes, activation = 'softmax')\n",
        "    ])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "b0NTboSKbnG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tune Learning Rate"
      ],
      "metadata": {
        "id": "t-6bB4gOfC4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to find the 'best' learning rate\n",
        "def adjust_learning_rate(dataset):\n",
        "    \n",
        "    model = create_uncompiled_model()\n",
        "    \n",
        "    lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch / 20))\n",
        "    \n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    \n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    history = model.fit(dataset, epochs=100, callbacks=[lr_schedule])\n",
        "    \n",
        "    return history"
      ],
      "metadata": {
        "id": "QUvsJdShcAQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Find the 'best' learning rate\n",
        "lr_history = adjust_learning_rate(train_ds)"
      ],
      "metadata": {
        "id": "KT4r0ZNHchCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Plot the result\n",
        "plt.semilogx(lr_history.history[\"lr\"], lr_history.history[\"loss\"])\n",
        "plt.axis([1e-4, 10, 0, 10])"
      ],
      "metadata": {
        "id": "m1TyuvXacmt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The 'best' learning rate would be around 1e-3 as that area has quite stable loss compared to the other area."
      ],
      "metadata": {
        "id": "4V2oMGEDd9pH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "wEmfb-fkfI1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_uncompiled_model()\n",
        "\n",
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=20)"
      ],
      "metadata": {
        "id": "RseiVTnoMiBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "JCOx-RgEOBQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.show()\n",
        "print(\"\")\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SLv5Q5s4Nn5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Model"
      ],
      "metadata": {
        "id": "HS1LY84Ofg1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# export_dir = 'saved_model/without_transfer_no_nothing'\n",
        "# tf.saved_model.save(model, export_dir)"
      ],
      "metadata": {
        "id": "gRqD5bd5fiU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save('saved_models/model_noaug_v3_0') "
      ],
      "metadata": {
        "id": "QzqxBdwj_M9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r \"/content/model_noaug_v3_0.zip\" \"/content/saved_models/model_noaug_v3_0\""
      ],
      "metadata": {
        "id": "s6XHN79h_Jcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !tensorflowjs_converter --input_format=keras_saved_model /content/saved_models/model_noaug_v3_0 ./"
      ],
      "metadata": {
        "id": "X0EmJZAs_Wqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With Transfer Learning\n",
        "\n"
      ],
      "metadata": {
        "id": "3LfeQj49gRDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Pre-trained Model"
      ],
      "metadata": {
        "id": "aTTsIMRZuGr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet_v2 = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
        "inception_v3 = \"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\"\n",
        "efficientnet_v0 = \"https://tfhub.dev/google/efficientnet/b0/feature-vector/1\"\n",
        "efficientnet_v0_lite = \"https://tfhub.dev/tensorflow/efficientnet/lite0/feature-vector/2\"\n",
        "\n",
        "feature_extractor_model = mobilenet_v2 #@param [\"mobilenet_v2\", \"inception_v3\", \"efficientnet_v0\", \"efficientnet_v0_lite\"] {type:\"raw\"}"
      ],
      "metadata": {
        "id": "YIqJFUCCuFN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create layer from pre-trained model\n",
        "feature_extractor_layer = hub.KerasLayer(\n",
        "    feature_extractor_model,\n",
        "    input_shape=(224, 224, 3),\n",
        "    trainable=False)"
      ],
      "metadata": {
        "id": "LDTmnAMLuS19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture"
      ],
      "metadata": {
        "id": "ciQb4fg7gREA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to create model\n",
        "def create_uncompiled_model():\n",
        "\n",
        "    num_classes = len(class_names)\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "      feature_extractor_layer,\n",
        "      tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "kKd9Xm6IgREB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tune Learning Rate"
      ],
      "metadata": {
        "id": "Nw0Z3-wKgREB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to find the 'best' learning rate\n",
        "def adjust_learning_rate(dataset):\n",
        "    \n",
        "    model = create_uncompiled_model()\n",
        "    \n",
        "    lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch / 20))\n",
        "    \n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    \n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    history = model.fit(dataset, epochs=100, callbacks=[lr_schedule])\n",
        "    \n",
        "    return history"
      ],
      "metadata": {
        "id": "5DSsrT4VgREB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Find the 'best' learning rate\n",
        "lr_history = adjust_learning_rate(train_ds)"
      ],
      "metadata": {
        "id": "5NRaxdRhgREB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Plot the result\n",
        "plt.semilogx(lr_history.history[\"lr\"], lr_history.history[\"loss\"])\n",
        "plt.axis([1e-4, 10, 0, 10])"
      ],
      "metadata": {
        "id": "I2Vg-p-xgREC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The 'best' learning rate would be around 0.005 as that area has quite \n",
        "stable loss compared to the other area."
      ],
      "metadata": {
        "id": "Cv5yB8GQgREC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "6QBy94_zgREC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_tl = create_uncompiled_model()\n",
        "\n",
        "model_tl.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.004),\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "history = model_tl.fit(train_ds, validation_data=val_ds, epochs=10)"
      ],
      "metadata": {
        "id": "vBKNNCzOgRED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "041f2008-9ace-4f32-da84-ac7594459d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "104/104 [==============================] - 45s 184ms/step - loss: 0.2121 - accuracy: 0.9577 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "104/104 [==============================] - 15s 140ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "104/104 [==============================] - 14s 135ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "104/104 [==============================] - 14s 135ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "104/104 [==============================] - 14s 135ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 9.8636e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "104/104 [==============================] - 14s 135ms/step - loss: 8.0232e-04 - accuracy: 1.0000 - val_loss: 7.8280e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "104/104 [==============================] - 14s 136ms/step - loss: 6.3705e-04 - accuracy: 1.0000 - val_loss: 6.4018e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "104/104 [==============================] - 15s 139ms/step - loss: 5.1954e-04 - accuracy: 1.0000 - val_loss: 5.3565e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "104/104 [==============================] - 14s 139ms/step - loss: 4.3259e-04 - accuracy: 1.0000 - val_loss: 4.5627e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "104/104 [==============================] - 14s 136ms/step - loss: 3.6619e-04 - accuracy: 1.0000 - val_loss: 3.9425e-04 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "EaNKYLkEgREE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.show()\n",
        "print(\"\")\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cSWzuFP6gREE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test with Uploaded Image"
      ],
      "metadata": {
        "id": "3IsTlVufzpH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Upload image(s) and predict\n",
        "# uploaded=files.upload()\n",
        "\n",
        "# # Load images\n",
        "# for fn in uploaded.keys():\n",
        " \n",
        "#   path='/content/' + fn\n",
        "#   img=load_img(path, target_size=(img_height, img_width))\n",
        "  \n",
        "#   x=img_to_array(img)\n",
        "#   x /= 255\n",
        "#   x=np.expand_dims(x, axis=0)\n",
        "#   images = np.vstack([x])\n",
        "  \n",
        "#   # Predict \n",
        "#   predicted_batch = model.predict(images)\n",
        "#   predicted_id = tf.math.argmax(predicted_batch, axis=-1)\n",
        "#   predicted_label_batch = class_names[predicted_id]\n",
        "#   print(predicted_label_batch)"
      ],
      "metadata": {
        "id": "29gf2zXz09dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Upload manually\n",
        "# path = '/content/dump/Photo on 26-05-23 at 19.01 copy.jpg'\n",
        "\n",
        "# image = PIL.Image.open(path)\n",
        "# image = image.resize((img_height, img_width), 1)\n",
        "# x=img_to_array(image)\n",
        "# x /= 255\n",
        "# x=np.expand_dims(x, axis=0)\n",
        "# images = np.vstack([x])\n",
        "\n",
        "# predicted_batch = model_tl.predict(images)\n",
        "# predicted_id = tf.math.argmax(predicted_batch, axis=-1)\n",
        "# predicted_label_batch = class_names[predicted_id]\n",
        "# print(predicted_label_batch)"
      ],
      "metadata": {
        "id": "xc4t1lQg9EdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test samples for specific class\n",
        "\n",
        "def create_test_generator(chosen_class):\n",
        "  path = '/content/drive/MyDrive/Capstone Project ML/Test samples/{}-samples'.format(chosen_class)\n",
        "\n",
        "  test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "  test_generator = test_datagen.flow_from_directory(path,\n",
        "                                classes=[chosen_class],\n",
        "                                class_mode=None,\n",
        "                                shuffle=False,\n",
        "                                target_size=(224, 224))\n",
        "  return test_generator"
      ],
      "metadata": {
        "id": "csLoJyGJONJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['A', 'B', 'C', 'D', 'E', 'F']\n",
        "\n",
        "for label in labels:\n",
        "  print(\"========================= Making predictions for class {} =========================\".format(label))\n",
        "\n",
        "  test_generator = create_test_generator(label)\n",
        "  predictions = model_tl.predict_generator(test_generator)\n",
        "\n",
        "  for prediction in predictions:\n",
        "    print(class_names[tf.math.argmax(prediction, axis=-1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqE5EbKiPIov",
        "outputId": "50131c24-f22a-4ece-f2bf-99db497d089b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================= Making predictions for class A =========================\n",
            "Found 5 images belonging to 1 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-274c02f711a6>:7: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  predictions = model_tl.predict_generator(test_generator)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "========================= Making predictions for class B =========================\n",
            "Found 10 images belonging to 1 classes.\n",
            "B\n",
            "B\n",
            "M\n",
            "B\n",
            "K\n",
            "M\n",
            "B\n",
            "B\n",
            "B\n",
            "B\n",
            "========================= Making predictions for class C =========================\n",
            "Found 10 images belonging to 1 classes.\n",
            "C\n",
            "C\n",
            "C\n",
            "E\n",
            "E\n",
            "K\n",
            "K\n",
            "K\n",
            "K\n",
            "I\n",
            "========================= Making predictions for class D =========================\n",
            "Found 10 images belonging to 1 classes.\n",
            "K\n",
            "K\n",
            "K\n",
            "K\n",
            "K\n",
            "T\n",
            "D\n",
            "T\n",
            "T\n",
            "D\n",
            "========================= Making predictions for class E =========================\n",
            "Found 10 images belonging to 1 classes.\n",
            "E\n",
            "E\n",
            "E\n",
            "Z\n",
            "Z\n",
            "E\n",
            "E\n",
            "E\n",
            "Z\n",
            "E\n",
            "========================= Making predictions for class F =========================\n",
            "Found 10 images belonging to 1 classes.\n",
            "F\n",
            "F\n",
            "F\n",
            "F\n",
            "F\n",
            "F\n",
            "F\n",
            "F\n",
            "F\n",
            "F\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Model"
      ],
      "metadata": {
        "id": "Pglv6SXMgREE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_tl.save('model_tl_noaug_bv0_0') \n",
        "\n",
        "# converter = tf.lite.TFLiteConverter.from_saved_model('model_tl_noaug_bv0_0')\n",
        "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# tflite_model = converter.convert()\n",
        "# tflite_model_file = 'model_tl_noaug_bv0_0.tflite'\n",
        "\n",
        "# with open(tflite_model_file, \"wb\") as f:\n",
        "#     f.write(tflite_model)\n",
        "\n",
        "# !zip -r \"/content/model_tl_noaug_bv0_0.zip\" \"/content/model_tl_noaug_bv0_0\""
      ],
      "metadata": {
        "id": "rTnNf8KtVRgw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcb240e3-672d-4f07-c07c-c9c0d18cf673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/model_tl_noaug_bv0_0/ (stored 0%)\n",
            "  adding: content/model_tl_noaug_bv0_0/keras_metadata.pb (deflated 80%)\n",
            "  adding: content/model_tl_noaug_bv0_0/fingerprint.pb (stored 0%)\n",
            "  adding: content/model_tl_noaug_bv0_0/variables/ (stored 0%)\n",
            "  adding: content/model_tl_noaug_bv0_0/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: content/model_tl_noaug_bv0_0/variables/variables.index (deflated 78%)\n",
            "  adding: content/model_tl_noaug_bv0_0/assets/ (stored 0%)\n",
            "  adding: content/model_tl_noaug_bv0_0/saved_model.pb (deflated 92%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r \"/content/model_tl_noaug_v4_3.zip\" \"/content/model_tl_noaug_v4_3\""
      ],
      "metadata": {
        "id": "3kjKcPYkAC9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import time\n",
        "# saved_model_path = \"./{}.h5\".format(int(time.time()))\n",
        "\n",
        "# model_tl.save(saved_model_path)"
      ],
      "metadata": {
        "id": "jFancqF3TZvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !tensorflowjs_converter --input_format=keras_saved_model --output_format=tfjs_graph_model inception_no_nothing_class ./"
      ],
      "metadata": {
        "id": "8Leq0TrtZU8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorrt"
      ],
      "metadata": {
        "id": "MPvmYDNn61x-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !tensorflowjs_converter --input_format=keras_saved_model /content/saved_models/model_tl_noaug_v4_01 ./"
      ],
      "metadata": {
        "id": "GoEI05xY6kkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade --index-url https://pypi.ngc.nvidia.com nvidia-tensorrt"
      ],
      "metadata": {
        "id": "o4AERvp-eLO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !tensorflowjs_converter --input_format=keras --output_format=tfjs_graph_model model_tl_noaug_v4_1.h5 ./ "
      ],
      "metadata": {
        "id": "Fwv7uNYCdMvz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}